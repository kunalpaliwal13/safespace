{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b8b5f5-4769-4851-95d7-271c7d89c7b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from textblob import TextBlob\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIO\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNAL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py:59\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     61\u001b[39m     ArrowDtype,\n\u001b[32m     62\u001b[39m     Int8Dtype,\n\u001b[32m     63\u001b[39m     Int16Dtype,\n\u001b[32m     64\u001b[39m     Int32Dtype,\n\u001b[32m     65\u001b[39m     Int64Dtype,\n\u001b[32m     66\u001b[39m     UInt8Dtype,\n\u001b[32m     67\u001b[39m     UInt16Dtype,\n\u001b[32m     68\u001b[39m     UInt32Dtype,\n\u001b[32m     69\u001b[39m     UInt64Dtype,\n\u001b[32m     70\u001b[39m     Float32Dtype,\n\u001b[32m     71\u001b[39m     Float64Dtype,\n\u001b[32m     72\u001b[39m     CategoricalDtype,\n\u001b[32m     73\u001b[39m     PeriodDtype,\n\u001b[32m     74\u001b[39m     IntervalDtype,\n\u001b[32m     75\u001b[39m     DatetimeTZDtype,\n\u001b[32m     76\u001b[39m     StringDtype,\n\u001b[32m     77\u001b[39m     BooleanDtype,\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     79\u001b[39m     NA,\n\u001b[32m     80\u001b[39m     isna,\n\u001b[32m     81\u001b[39m     isnull,\n\u001b[32m     82\u001b[39m     notna,\n\u001b[32m     83\u001b[39m     notnull,\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     85\u001b[39m     Index,\n\u001b[32m     86\u001b[39m     CategoricalIndex,\n\u001b[32m     87\u001b[39m     RangeIndex,\n\u001b[32m     88\u001b[39m     MultiIndex,\n\u001b[32m     89\u001b[39m     IntervalIndex,\n\u001b[32m     90\u001b[39m     TimedeltaIndex,\n\u001b[32m     91\u001b[39m     DatetimeIndex,\n\u001b[32m     92\u001b[39m     PeriodIndex,\n\u001b[32m     93\u001b[39m     IndexSlice,\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     95\u001b[39m     NaT,\n\u001b[32m     96\u001b[39m     Period,\n\u001b[32m     97\u001b[39m     period_range,\n\u001b[32m     98\u001b[39m     Timedelta,\n\u001b[32m     99\u001b[39m     timedelta_range,\n\u001b[32m    100\u001b[39m     Timestamp,\n\u001b[32m    101\u001b[39m     date_range,\n\u001b[32m    102\u001b[39m     bdate_range,\n\u001b[32m    103\u001b[39m     Interval,\n\u001b[32m    104\u001b[39m     interval_range,\n\u001b[32m    105\u001b[39m     DateOffset,\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    107\u001b[39m     to_numeric,\n\u001b[32m    108\u001b[39m     to_datetime,\n\u001b[32m    109\u001b[39m     to_timedelta,\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    111\u001b[39m     Flags,\n\u001b[32m    112\u001b[39m     Grouper,\n\u001b[32m    113\u001b[39m     factorize,\n\u001b[32m    114\u001b[39m     unique,\n\u001b[32m    115\u001b[39m     value_counts,\n\u001b[32m    116\u001b[39m     NamedAgg,\n\u001b[32m    117\u001b[39m     array,\n\u001b[32m    118\u001b[39m     Categorical,\n\u001b[32m    119\u001b[39m     set_eng_float_format,\n\u001b[32m    120\u001b[39m     Series,\n\u001b[32m    121\u001b[39m     DataFrame,\n\u001b[32m    122\u001b[39m )\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNAL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     NaT,\n\u001b[32m      3\u001b[39m     Period,\n\u001b[32m      4\u001b[39m     Timedelta,\n\u001b[32m      5\u001b[39m     Timestamp,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     ArrowDtype,\n\u001b[32m     11\u001b[39m     CategoricalDtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     PeriodDtype,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KUNAL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     NaT,\n\u001b[32m     21\u001b[39m     NaTType,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     iNaT,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32minterval.pyx:1\u001b[39m, in \u001b[36minit pandas._libs.interval\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# from textblob import TextBlob\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72126a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\kunal\\appdata\\roaming\\python\\python313\\site-packages (2.2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\kunal\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kunal\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kunal\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kunal\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kunal\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: C:\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3686b7dc-3a3b-452f-8560-f02884bfd6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KUNAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KUNAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2a4e3e-4e97-4846-9899-86ace34f150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am not feeling well\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3125b3c-e76e-434f-a6a5-572544370b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score = TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e59c2118-2e8e-4bb5-bd55-0109db586bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = \"positive\" if sentiment_score > 0 else \"negative\" if sentiment_score < 0 else \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "053167bc-531e-425a-99eb-341cbc464262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neutral'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "({\"sentiment\": sentiment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69aad014-0084-452e-bea4-a8e0e7fd705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt/train.txt', 'r') as file:\n",
    "        data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f541c850-a499-4187-9297-ee20d6469667",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_io = StringIO(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "126ff50c-c35b-4e69-9bb2-3a432e65067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "emotions = []\n",
    "\n",
    "for line in data_io:\n",
    "    line = line.strip()  \n",
    "    if line:  \n",
    "        parts = line.split(';')\n",
    "        if len(parts) == 2:\n",
    "            texts.append(parts[0])\n",
    "            emotions.append(parts[1])\n",
    "        else:\n",
    "            print(f\"Warning: Skipping malformed line - '{line}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f31063c-db5d-4632-b218-8e68aeb34a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': texts, 'emotion': emotions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a201853e-3b49-4e52-b432-75fa3fab3f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97b91879-85c6-4ae9-9710-e1ac26a350fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "joy           5362\n",
      "sadness       4665\n",
      "anger         2159\n",
      "fear          1937\n",
      "love          1304\n",
      "suicidal      1024\n",
      "depression    1000\n",
      "surprise       967\n",
      "sadnessa         1\n",
      "suicidalf        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_counts = df['emotion'].value_counts()\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b52ad045-2303-41ee-b301-2c80f7f1d4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i think it s the easiest time of year to feel ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel irritated and rejected without anyone d...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i already feel like i fucked up though because...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion\n",
       "0   im grabbing a minute to post i feel greedy wrong   anger\n",
       "1                               i am feeling grouchy   anger\n",
       "2  i think it s the easiest time of year to feel ...   anger\n",
       "3  i feel irritated and rejected without anyone d...   anger\n",
       "4  i already feel like i fucked up though because...   anger"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('emotion')\n",
    "\n",
    "limited_df = pd.DataFrame()\n",
    "\n",
    "for emotion, group in grouped:\n",
    "    limited_group = group.head(950)\n",
    "    limited_df = pd.concat([limited_df, limited_group])\n",
    "\n",
    "limited_df = limited_df.reset_index(drop=True)\n",
    "\n",
    "limited_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5a5f508-3e81-4cf2-aa61-504fed22138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "anger         950\n",
      "depression    950\n",
      "fear          950\n",
      "joy           950\n",
      "love          950\n",
      "sadness       950\n",
      "suicidal      950\n",
      "surprise      950\n",
      "sadnessa        1\n",
      "suicidalf       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_counts = limited_df['emotion'].value_counts()\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0bd65a1-9e0c-429c-b137-f0c1886cde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_to_delete = ['suicidalf', 'sadnessa']\n",
    "indices_to_drop = []\n",
    "\n",
    "for index, row in limited_df.iterrows():\n",
    "    if row['emotion'] in emotions_to_delete:\n",
    "        indices_to_drop.append(index)\n",
    "\n",
    "df_cleaned = limited_df.drop(indices_to_drop)\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6438fe0b-90cb-435e-9104-a06126c34cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text   emotion\n",
      "0      im grabbing a minute to post i feel greedy wrong     anger\n",
      "1                                  i am feeling grouchy     anger\n",
      "2     i think it s the easiest time of year to feel ...     anger\n",
      "3     i feel irritated and rejected without anyone d...     anger\n",
      "4     i already feel like i fucked up though because...     anger\n",
      "...                                                 ...       ...\n",
      "7595  I was shocked by how smooth the entire experie...  surprise\n",
      "7596     I didnâ€™t think Iâ€™d be able to get this far  surprise\n",
      "7597  I didnâ€™t think Iâ€™d enjoy the process this ...  surprise\n",
      "7598           Iâ€™m shocked by how much Iâ€™ve learned  surprise\n",
      "7599  I didnâ€™t think it would be this enjoyable, b...  surprise\n",
      "\n",
      "[7600 rows x 2 columns]\n",
      "emotion\n",
      "anger         950\n",
      "depression    950\n",
      "fear          950\n",
      "joy           950\n",
      "love          950\n",
      "sadness       950\n",
      "suicidal      950\n",
      "surprise      950\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned)\n",
    "print(df_cleaned['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd7e3232-aa36-475e-9492-44fc5589b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())  # lowercase the text and tokenize it\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalnum()]\n",
    "    \n",
    "    # Rejoin tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_cleaned['preprocessed_text'] = df_cleaned['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "020179d7-471f-45e2-8b06-d0f71db8c883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>feeling grouchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i think it s the easiest time of year to feel ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>think easiest time year feel dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel irritated and rejected without anyone d...</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel irritated rejected without anyone anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i already feel like i fucked up though because...</td>\n",
       "      <td>anger</td>\n",
       "      <td>already feel like fucked though dont usually e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion  \\\n",
       "0   im grabbing a minute to post i feel greedy wrong   anger   \n",
       "1                               i am feeling grouchy   anger   \n",
       "2  i think it s the easiest time of year to feel ...   anger   \n",
       "3  i feel irritated and rejected without anyone d...   anger   \n",
       "4  i already feel like i fucked up though because...   anger   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0          im grabbing minute post feel greedy wrong  \n",
       "1                                    feeling grouchy  \n",
       "2          think easiest time year feel dissatisfied  \n",
       "3  feel irritated rejected without anyone anythin...  \n",
       "4  already feel like fucked though dont usually e...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9627f48b-6fb6-45af-9c9b-d6e0b4ac8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned['preprocessed_text']\n",
    "y = df_cleaned['emotion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3b66a14-e78b-494a-800a-a84640736b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6080,) (6080,) (1520,) (1520,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1a3d8a1-6de9-4d2b-9733-f346a36311d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5901cef-98d9-4d4b-b5f8-0ff9198d0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.82      0.78      0.80       190\n",
      "  depression       0.95      1.00      0.98       190\n",
      "        fear       0.75      0.79      0.77       190\n",
      "         joy       0.83      0.72      0.77       190\n",
      "        love       0.82      0.84      0.83       190\n",
      "     sadness       0.81      0.67      0.73       190\n",
      "    suicidal       0.90      1.00      0.95       190\n",
      "    surprise       0.75      0.84      0.79       190\n",
      "\n",
      "    accuracy                           0.83      1520\n",
      "   macro avg       0.83      0.83      0.83      1520\n",
      "weighted avg       0.83      0.83      0.83      1520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2707e18-cf44-40d7-82a2-bab73ef76b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 emotions with probability for 'I want to kill myself!' are:  {'fear, suicidal'}\n",
      "Top 2 emotions with probability for 'I am so happy' are:  {'surprise, joy'}\n",
      "Top 2 emotions with probability for 'I dont know what to do with my life anymore' are:  {'sadness, anger'}\n",
      "Top 2 emotions with probability for 'I did not expect you here' are:  {'joy, surprise'}\n",
      "Top 2 emotions with probability for 'I feel hopeless' are:  {'depression, suicidal'}\n"
     ]
    }
   ],
   "source": [
    "def predict_emotion(text):\n",
    "    processed_text = preprocess_text(text)\n",
    "    text_tfidf = vectorizer.transform([processed_text])\n",
    "    return model.predict(text_tfidf)\n",
    "\n",
    "# Test with a new entry\n",
    "new_entry = [\"I want to kill myself!\", \"I am so happy\", \"I dont know what to do with my life anymore\", \"I did not expect you here\", \"I feel hopeless\"]\n",
    "for text in new_entry:\n",
    "    processed_text = preprocess_text(text)\n",
    "    text_tfidf = vectorizer.transform([processed_text])\n",
    "    probs = model.predict_proba(text_tfidf)[0]\n",
    "    top_2_indices = probs.argsort()[-2:]\n",
    "    top_2_emotions = [model.classes_[index] for index in top_2_indices]\n",
    "    top_2_probs = probs[top_2_indices]\n",
    "    print(f\"Top 2 emotions with probability for '{text}' are: \", {', '.join(top_2_emotions)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f233134-ea0c-46e2-82ce-0de5a187d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('emotion_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9ddf8-0d77-4b0d-9a2f-f5be9f536951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
