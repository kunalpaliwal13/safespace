{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e756b23d-e89a-4851-8932-20671f715aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f568f086-109b-4d4e-934a-5e0147f5fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('suicidal_sentiment_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fe2941-bd68-4d4a-a671-e0d5bcf9dc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m grateful for my family</td>\n",
       "      <td>not suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm tired of existing</td>\n",
       "      <td>suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life feels meaningless</td>\n",
       "      <td>suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had a good day</td>\n",
       "      <td>not suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m proud of myself</td>\n",
       "      <td>not suicidal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text         label\n",
       "0  I’m grateful for my family  not suicidal\n",
       "1       I'm tired of existing      suicidal\n",
       "2      Life feels meaningless      suicidal\n",
       "3            I had a good day  not suicidal\n",
       "4         I’m proud of myself  not suicidal"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2cf343-2414-4067-8ad8-156b91c56d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "not suicidal    2500\n",
      "suicidal        2500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_counts = df['label'].value_counts()\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93169996-ebab-4569-b323-cb2681640121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())  # lowercase the text and tokenize it\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalnum()]\n",
    "    \n",
    "    # Rejoin tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06e46d0e-3c4d-4f34-8355-60211d3313b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['preprocessed_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d9c3988-a28c-4f0f-9b90-b4c6bbb25a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8598296e-b2f4-4b63-bcab-0fa71a7205dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [100, 200]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    \"Multinomial Naive Bayes\": {\n",
    "        'alpha': [0.1, 0.5, 1.0]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abd46282-1d54-4c70-a2e2-a0ccc470dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n",
      "Best Parameters: {'C': 0.1, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not suicidal       1.00      1.00      1.00       500\n",
      "    suicidal       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "==================================================\n",
      "Evaluating SVC...\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not suicidal       1.00      1.00      1.00       500\n",
      "    suicidal       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "==================================================\n",
      "Evaluating Multinomial Naive Bayes...\n",
      "Best Parameters: {'alpha': 0.1}\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not suicidal       1.00      1.00      1.00       500\n",
      "    suicidal       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(model, param_grids[model_name], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    grid_search.fit(X_train_tfidf, y_train)  # Train with grid search\n",
    "\n",
    "    # Get the best model and its parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = best_model.predict(X_train_tfidf)\n",
    "    y_test_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "    # Print the best parameters and accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_test, y_test_pred)}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84f50aef-5cf4-4a3d-aafd-9b96617cf43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not suicidal       1.00      1.00      1.00       500\n",
      "    suicidal       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = SVC(C=1, gamma='scale', kernel='linear')\n",
    "final_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_train_pred = final_model.predict(X_train_tfidf)\n",
    "y_test_pred = final_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23f787dd-8137-4b30-8271-21eba370acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suicidal']\n",
      "['not suicidal']\n",
      "['suicidal']\n",
      "['not suicidal']\n",
      "['not suicidal']\n",
      "['not suicidal']\n"
     ]
    }
   ],
   "source": [
    "def predict_emotion(text):\n",
    "    processed_text = preprocess_text(text)\n",
    "    text_tfidf = vectorizer.transform([processed_text])\n",
    "    return final_model.predict(text_tfidf)\n",
    "\n",
    "# Test with a new entry\n",
    "new_entry = [\"I want to kill myself\", \"I am so happy\", \"I dont know what to do with my life anymore\", \"I did not expect you here\", \"I feel hopeless\", \"I wanna kill myself\"]\n",
    "for i in new_entry:\n",
    "    print(predict_emotion(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43003c36-6171-4b4d-83f7-c9a8499fa628",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiemotion_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m binary_y = [\u001b[33m'\u001b[39m\u001b[33msuicidal\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label == \u001b[33m'\u001b[39m\u001b[33msuicidal\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mnot suicidal\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmultiemotion_y\u001b[49m]\n",
      "\u001b[31mNameError\u001b[39m: name 'multiemotion_y' is not defined"
     ]
    }
   ],
   "source": [
    "binary_y = ['suicidal' if label == 'suicidal' else 'not suicidal' for label in multiemotion_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6717de07-286e-4103-bf4f-acd70c0de3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the TXT file (1 line = 1 entry)\n",
    "with open('train.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "data = [line.strip().split(';') for line in lines if ';' in line]\n",
    "df = pd.DataFrame(data, columns=['text', 'label'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ca90fa3-a74b-459b-ac14-bb98b9f1b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi= pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99f6bfad-6fca-448b-bde8-df611004184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b3fc978-404d-42bf-b43e-c6d68164002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi['binary_label'] = df_multi['label'].apply(lambda x: 'suicidal' if x == 'suicidal' else 'not suicidal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3aca9cb-d892-41d7-9a0c-e7710d64a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the preprocessed text\n",
    "X_multi_tfidf = vectorizer.transform(df_multi['preprocessed_text'])\n",
    "\n",
    "# Now you can predict\n",
    "pred = final_model.predict(X_multi_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f28bd50-dee6-420e-9d3e-af1c337d09ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(df_multi['binary_label'], pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d456f4dd-5764-4924-8e75-8f78ec32b319",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'didnt feel humiliated'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df_multi[\u001b[33m'\u001b[39m\u001b[33mpreprocessed_text\u001b[39m\u001b[33m'\u001b[39m] = df_multi[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].apply(preprocess_text)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pred = \u001b[43mfinal_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_multi\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpreprocessed_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(pred,\u001b[38;5;250m \u001b[39mdf_multi[\u001b[33m'\u001b[39m\u001b[33mbinary_label\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\svm\\_base.py:822\u001b[39m, in \u001b[36mBaseSVC.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    820\u001b[39m     y = np.argmax(\u001b[38;5;28mself\u001b[39m.decision_function(X), axis=\u001b[32m1\u001b[39m)\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     y = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_.take(np.asarray(y, dtype=np.intp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\svm\\_base.py:436\u001b[39m, in \u001b[36mBaseLibSVM.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    421\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[32m    422\u001b[39m \n\u001b[32m    423\u001b[39m \u001b[33;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m \u001b[33;03m        The predicted values.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m     predict = \u001b[38;5;28mself\u001b[39m._sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dense_predict\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\svm\\_base.py:614\u001b[39m, in \u001b[36mBaseLibSVM._validate_for_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    611\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.kernel):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(X):\n\u001b[32m    625\u001b[39m     X = sp.csr_matrix(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    837\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\series.py:1031\u001b[39m, in \u001b[36mSeries.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[33;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[32m    983\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m \u001b[33;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[32m   1029\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1030\u001b[39m values = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m arr = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values.dtype, arr.dtype):\n\u001b[32m   1033\u001b[39m     arr = arr.view()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'didnt feel humiliated'"
     ]
    }
   ],
   "source": [
    "df_multi['preprocessed_text'] = df_multi['text'].apply(preprocess_text)\n",
    "pred = final_model.predict(df_multi['preprocessed_text'])\n",
    "print(f\"Test Accuracy: {accuracy_score(pred, df_multi['binary_label']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4877d2e-bef7-4b29-8fd6-37b75ff018d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
